// Importamos los clientes de Google Cloud necesarios
import { Firestore } from "@google-cloud/firestore";
import { VertexAI } from "@google-cloud/vertexai";
import { v1 } from "@google-cloud/discoveryengine";
const discoveryengineClient = new v1.SearchServiceClient();

// Leemos las variables de entorno necesarias
const projectId = process.env.NEXT_PUBLIC_FIREBASE_PROJECT_ID;
const location = process.env.VERTEX_AI_LOCATION || "us-central1"; // Regi√≥n por defecto
const firestoreDatabaseId = process.env.FIRESTORE_DATABASE_ID || "(default)";
const vertexAiSearchDataStoreId = process.env.VERTEX_AI_SEARCH_DATA_STORE_ID;

import { GoogleAuth } from 'google-auth-library';

const credentialsJSON = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;

if (!credentialsJSON) {
  throw new Error("‚ùå Falta la variable de entorno GOOGLE_APPLICATION_CREDENTIALS_JSON.");
}

const auth = new GoogleAuth({
  credentials: JSON.parse(credentialsJSON),
  scopes: ['https://www.googleapis.com/auth/cloud-platform'],
});

const authClient = await auth.getClient();
const project = await auth.getProjectId();
console.log("‚úÖ Autenticado en proyecto:", project);



if (!process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON) {
  throw new Error("‚ùå GOOGLE_APPLICATION_CREDENTIALS_JSON no est√° definida.");
}

const rawCredentials = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;
if (!rawCredentials) {
  throw new Error("‚ùå Falta la variable GOOGLE_APPLICATION_CREDENTIALS_JSON");
}
const credentials = JSON.parse(rawCredentials);



// Verificamos que las variables clave est√©n definidas
if (
  !projectId ||
  !process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON ||
  !vertexAiSearchDataStoreId
) {
  console.error("‚ùå Faltan variables de entorno requeridas.");
  // En producci√≥n deber√≠as retornar un error HTTP aqu√≠.
}

// üî• Inicializamos el cliente de Firestore
const firestore = new Firestore({
  projectId: projectId,
  databaseId: firestoreDatabaseId,
  credentials,
});

// ü§ñ Inicializamos el cliente de Vertex AI
const vertex_ai = new VertexAI({
  project: projectId,
  location: location,
  credentials, // <- pasamos el objeto directamente
});

// üì¶ Construimos el nombre completo del data store para las b√∫squedas
const dataStoreName = `projects/${projectId}/locations/global/collections/default_collection/dataStores/${vertexAiSearchDataStoreId}`;

// ‚ú® Creamos el modelo generativo Gemini-Pro
const generativeModel = vertex_ai.getGenerativeModel({
    model: 'gemini-2.0-flash-lite-001',
});

// Handler para el endpoint /api/chat (Next.js o API Route en App Router)
export async function POST(req) {
  const { query: userQuery } = await req.json();

  // Saludo inicial o mensaje vac√≠o
  if (userQuery.trim() === "" || userQuery.toLowerCase().includes("hola")) {
    const bienvenida = `¬°Hola! üëã Un placer saludarte. 
¬øEn qu√© puedo ayudarte hoy a encontrar una propiedad? ¬øTienes alguna idea de lo que est√°s buscando? ¬øPor ejemplo, te interesa comprar, alquilar, en qu√© zona te gustar√≠a, qu√© tipo de propiedad tienes en mente (piso, casa, local comercial...)? Cu√©ntame un poco m√°s sobre tus necesidades para poder ayudarte mejor. üòä`;

    return new Response(
      JSON.stringify({
        conversationalResponse: bienvenida,
        propertyResults: [],
      }),
      {
        status: 200,
        headers: { "Content-Type": "application/json" },
      }
    );
  }

  if (!userQuery) {
    return new Response(
      JSON.stringify({ error: "Missing user query in request body" }),
      {
        status: 400,
        headers: { "Content-Type": "application/json" },
      }
    );
  }

  let conversationalResponse = "Lo siento, no pude procesar tu solicitud.";
  let propertyResults = [];
  let searchParameters = {};

  try {
    // üß† Paso 1: Gemini intenta extraer criterios de b√∫squeda
    const prompt = `Eres un asistente especializado en propiedades inmobiliarias en Espa√±a. Tu tarea es analizar el mensaje del usuario y extraer criterios de b√∫squeda relevantes. Devuelve un objeto JSON con campos como:

    - municipio_catastro
    - provincia_catastro
    - price_approx (puede tener min y/o max)
    - superficie_construida_m2
    - rooms
    - bathrooms
    - property_type o Property Type
    - uso_predominante_inmueble
    - precio_idealista_venta_m2
    - tipo_procedimiento
    - fase_procedimiento
    - estado_posesion_fisica
    - has_parking;
    
    Si no puedes identificar ning√∫n criterio, devuelve '{}'. 
    Si el mensaje del usuario no es una b√∫squeda, ign√≥ralo y responde '{}'.
    
    Mensaje del usuario: "${userQuery}"
    
    Salida JSON:`;

    const geminiResponse = await generativeModel.generateContent(prompt);
console.log('üîç Respuesta cruda desde Vertex AI:', JSON.stringify(geminiResponse, null, 2));
    const geminiText =
      geminiResponse.response.candidates[0]?.content?.parts[0]?.text;

    try {
      // Extraemos el JSON desde el texto generado por Gemini (puede tener ruido o formato suelto)
      const jsonMatch = geminiText.match(/\{.*\}/s);
      if (jsonMatch && jsonMatch[0]) {
        searchParameters = JSON.parse(jsonMatch[0]);
      } else {
        console.warn("‚ö†Ô∏è Gemini no devolvi√≥ JSON v√°lido:", geminiText);
        const fallbackPrompt = `El usuario ha dicho: "${userQuery}". No he podido extraer criterios de b√∫squeda claros. Formula una respuesta conversacional en espa√±ol, educada y amigable, y haz una o dos preguntas para ayudar a concretar mejor qu√© tipo de propiedad busca, por ejemplo: ubicaci√≥n, tipo, precio, n√∫mero de habitaciones, etc.`;
        const fallbackResponse = await generativeModel.generateContent(
          fallbackPrompt
        );
        conversationalResponse =
          fallbackResponse.response.candidates[0]?.content?.parts[0]?.text;
        return new Response(
          JSON.stringify({ conversationalResponse, propertyResults }),
          {
            status: 200,
            headers: { "Content-Type": "application/json" },
          }
        );
      }
    } catch (parseError) {
      console.error("‚ùå Error al parsear el JSON de Gemini:", parseError);
      console.log("Texto bruto de Gemini:", geminiText);
      const fallbackPrompt = `El usuario dijo: "${userQuery}". Hubo un error al procesar la solicitud. Genera una respuesta en espa√±ol, amigable, pidiendo disculpas por el error. Usa Markdown para dar formato.`;
      const fallbackResponse = await generativeModel.generateContent(
        fallbackPrompt
      );
      conversationalResponse =
        fallbackResponse.response.candidates[0]?.content?.parts[0]?.text;
      return new Response(
        JSON.stringify({
          error: "Error processing query.",
          conversationalResponse,
        }),
        {
          status: 500,
          headers: { "Content-Type": "application/json" },
        }
      );
    }

    // üîç Paso 2: Si hay par√°metros v√°lidos, hacemos b√∫squeda en Vertex AI Search
    if (Object.keys(searchParameters).length > 0) {
      console.log("üîé Par√°metros de b√∫squeda extra√≠dos:", searchParameters);

      const searchRequest = {
        servingConfig: `${dataStoreName}/servingConfigs/default_serving_config`,
        query: userQuery,
        queryExpansionSpec: { condition: "AUTO" },
        spellCorrectionSpec: { mode: "AUTO" },
        filter: buildVertexAISearchFilter(searchParameters),
      };

      console.log(
        "üõ† Enviando b√∫squeda a Vertex AI Search:",
        JSON.stringify(searchRequest, null, 2)
      );

      const [searchResponse] = await discoveryengineClient.search(
        searchRequest
      );

      // Extraemos los resultados del documento (seg√∫n c√≥mo configuraste la indexaci√≥n)
      propertyResults =
        searchResponse.results
          ?.map((result) => {
            try {
              // Verifica que `result.document.content?.jsonData` exista
              const rawJson = result.document?.content?.jsonData;
              return rawJson ? JSON.parse(rawJson) : null;
            } catch (e) {
              console.error("‚ùå Error parseando resultado:", e);
              return null;
            }
          })
          .filter((item) => item !== null) || [];

      console.log(`‚úÖ ${propertyResults.length} propiedades encontradas.`);

      // üß† Paso 3: Creamos una respuesta conversacional usando Gemini
      if (propertyResults.length > 0) {
        const resultSummaryPrompt = `El usuario busca propiedades bas√°ndose en: "${userQuery}". He encontrado ${
          propertyResults.length
        } propiedades. Aqu√≠ tienes un resumen de las primeras 3 para generar una respuesta conversacional en espa√±ol (usa Markdown para formato):

  - Menciona cu√°ntas propiedades se encontraron.
  - Resalta 2-3 caracter√≠sticas clave de cada una.
  - Termina animando al usuario a consultar m√°s o a afinar su b√∫squeda.
  `;

        const conversationalResponseGen = await generativeModel.generateContent(
          resultSummaryPrompt
        );
        conversationalResponse =
          conversationalResponseGen.response.candidates[0]?.content?.parts[0]
            ?.text;
      } else {
        const noResultsPrompt = `El usuario buscaba propiedades con base en: "${userQuery}", pero no se encontraron resultados. Responde en tono amistoso en espa√±ol, menciona que no hay coincidencias y sugiere amablemente cambiar algunos criterios. Tambi√©n puedes hacer una pregunta para orientar mejor la b√∫squeda.
`;
        const noResultsResponse = await generativeModel.generateContent(
          noResultsPrompt
        );
        conversationalResponse =
          noResultsResponse.response.candidates[0]?.content?.parts[0]?.text;
      }
    } else {
      // No se identificaron par√°metros de b√∫squeda: respuesta gen√©rica
      const generalResponsePrompt = `El usuario dijo: "${userQuery}". No se identificaron criterios espec√≠ficos de b√∫squeda. Responde en espa√±ol, de forma conversacional, y preg√∫ntale c√≥mo puedes ayudarle a encontrar una propiedad. Usa formato Markdown.`;
      const generalResponse = await generativeModel.generateContent(
        generalResponsePrompt
      );
      conversationalResponse =
        generalResponse.response.candidates[0]?.content?.parts[0]?.text;
    }

    // ‚úÖ Paso 4: Respondemos al frontend
    return new Response(
      JSON.stringify({
        conversationalResponse,
        propertyResults,
      }),
      {
        status: 200,
        headers: { "Content-Type": "application/json" },
      }
    );
  } catch (error) {
    console.error("‚ùå Error general en el endpoint /api/chat:", error);

    try {
      const errorPrompt = `Hubo un error t√©cnico al procesar la solicitud del usuario: "${userQuery}". Genera una respuesta conversacional en espa√±ol, disculp√°ndote por las molestias e invitando al usuario a intentarlo de nuevo m√°s tarde. Usa formato Markdown.`;
      const errorResponseGen = await generativeModel.generateContent(
        errorPrompt
      );
      conversationalResponse =
        errorResponseGen.response.candidates[0]?.content?.parts[0]?.text;
    } catch (genError) {
      console.error("‚ö†Ô∏è Fallo generando respuesta de error:", genError);
      conversationalResponse =
        "Lo siento, ha ocurrido un error inesperado. Por favor, intenta de nuevo m√°s tarde.";
    }

    return new Response(
      JSON.stringify({
        error: "Internal Server Error",
        conversationalResponse,
        propertyResults: [],
      }),
      {
        status: 500,
        headers: { "Content-Type": "application/json" },
      }
    );
  }
}
// üîß Funci√≥n auxiliar para construir el filtro de Vertex AI Search
function buildVertexAISearchFilter(params) {
  const filters = [];

  const fieldMap = {
    municipio_catastro: "municipio_catastro",
    provincia_catastro: "provincia_catastro",
    "Property Type": "Property Type",
    property_type: "property_type",
    tipo_procedimiento: "tipo_procedimiento",
    fase_procedimiento: "fase_procedimiento",
    fase_actual: "fase_actual",
    rooms: "rooms",
    bathrooms: "bathrooms",
    has_parking: "has_parking",
    uso_predominante_inmueble: "uso_predominante_inmueble",
    superficie_construida_m2: "superficie_construida_m2",
    ano_construccion_inmueble: "ano_construccion_inmueble",
    precio_idealista_venta_m2: "precio_idealista_venta_m2",
    precio_idealista_alquiler_m2: "precio_idealista_alquiler_m2",
    price_approx: "price_approx",
    auction_value: "auction_value",
    purchase_price: "purchase_price"
  };

  for (const key in params) {
    const value = params[key];
    const field = fieldMap[key];
    if (!field || value === undefined || value === null) continue;

    if (typeof value === 'number') {
      filters.push(`${field} = ${value}`);
    } else if (typeof value === 'string') {
      filters.push(`${field}:"${value}"`);
    } else if (typeof value === 'object' && value.min !== undefined && value.max !== undefined) {
      filters.push(`${field} >= ${value.min} AND ${field} <= ${value.max}`);
    }
  }

  return filters.join(" AND ");
}